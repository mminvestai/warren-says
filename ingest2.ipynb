{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mminvestai/warren-says/blob/main/ingest2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xefqjmsudYB",
        "outputId": "41bda013-6d92-442a-ee13-01c31694bdea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.80)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.28.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import logging\n",
        "import re\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam.io import ReadFromText\n",
        "from apache_beam.io import WriteToText\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.options.pipeline_options import SetupOptions\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "\n",
        "def consolidate(df_daily, df_interval, interval):\n",
        "    if df_interval.empty == True:\n",
        "        df_interval.rename(columns = {interval: 'date'}, inplace = True)\n",
        "        df_consolidated = df_daily.merge(df_interval, on = ['date'], how='outer')\n",
        "    else:\n",
        "        if interval == 'date':\n",
        "            df_consolidated = df_daily.merge(df_interval, on = ['date'], how='outer')\n",
        "        else:\n",
        "            if interval == 'week':\n",
        "                df_interval['week'] = (df_interval['date'].dt.week % 52) + 1\n",
        "                df_daily['week'] = df_daily['date'].dt.week\n",
        "            elif interval == 'month':\n",
        "                df_interval['month'] = (df_interval['date'].dt.month % 12) + 1\n",
        "                df_daily['month'] = df_daily['date'].dt.month\n",
        "            elif interval == 'quarter':\n",
        "                df_interval['quarter'] = (df_interval['date'].dt.quarter % 4) + 1\n",
        "                df_daily['quarter'] = df_daily['date'].dt.quarter\n",
        "            df_interval['year'] = 0\n",
        "            df_interval.loc[df_interval[interval] == 1, 'year'] = df_interval['date'].dt.year + 1\n",
        "            df_interval.loc[df_interval[interval] != 1, 'year'] = df_interval['date'].dt.year\n",
        "            df_daily['year'] = df_daily['date'].dt.year\n",
        "            df_interval = df_interval.drop(columns=['date'])\n",
        "            df_consolidated = df_daily.merge(df_interval, on = [interval, 'year'], how='outer')\n",
        "            df_consolidated = df_consolidated.drop(columns=['year'])\n",
        "            df_consolidated = df_consolidated.drop(columns=[interval])\n",
        "    col = df_consolidated.pop('date')\n",
        "    df_consolidated.insert(0, 'date', col)\n",
        "    return df_consolidated\n",
        "\n",
        "def run(argv=None, save_main_session=True):\n",
        "  data_temp_list = []\n",
        "\n",
        "  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument(\n",
        "      '--input',\n",
        "      dest='input',\n",
        "      #default='gs://dataflow-samples/shakespeare/kinglear.txt',\n",
        "      #required=False,\n",
        "      required=True,\n",
        "      help='Input file to process.')\n",
        "  parser.add_argument(\n",
        "      '--output',\n",
        "      dest='output',\n",
        "      required=True,\n",
        "      help='Output file to write results to.')\n",
        "  known_args, pipeline_args = parser.parse_known_args(argv)\n",
        "\n",
        "  # We use the save_main_session option because one or more DoFn's in this\n",
        "  # workflow rely on global context (e.g., a module imported at module level).\n",
        "  pipeline_options = PipelineOptions(pipeline_args)\n",
        "  pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n",
        "\n",
        "  # The pipeline will be run on exiting the with block.\n",
        "  with beam.Pipeline(options=pipeline_options) as p:\n",
        "\n",
        "    # Read the text file[pattern] into a PCollection.\n",
        "    ticker_list = pd.read_csv(known_args.input)['ticker']\n",
        "\n",
        "    for ticker in ticker_list:\n",
        "      df_list = []\n",
        "      \n",
        "      # Yahoo Finance Dividend and Splits\n",
        "      running = True\n",
        "      while running:\n",
        "        try:\n",
        "          temp = yf.Ticker(ticker).history(period=\"max\")[['Dividends', 'Stock Splits']].reset_index().sort_values(by=['Date']).rename(columns={'Date': 'date'})\n",
        "          running = False\n",
        "        except:\n",
        "          sleep(1)\n",
        "      df_list.append(temp)\n",
        "\n",
        "      # Yahoo Finance Stock Prices\n",
        "      error = 1\n",
        "      while error == 1:\n",
        "        temp = yf.download(ticker)[['Open',\t'High',\t'Low', 'Close', 'Adj Close', 'Volume']].reset_index().sort_values(by=['Date']).rename(columns={'Date': 'date'})\n",
        "        if len(temp) == 0:\n",
        "          sleep(1)\n",
        "        else:\n",
        "            error = 0\n",
        "      df_list.append(temp)\n",
        "      \n",
        "      # Nasdaq Quandl Options Implied Volatility\n",
        "      #temp = quandl.get(\"VOL/\"+opt_ticker)[['Hv10','Hv180','Phv10','Phv180','IvCall10','IvPut10','IvCall1080','IvPut1080']].reset_index().sort_values(by=['Date']).rename(columns={'Date': 'date'})\n",
        "      #df_list.append(temp)\n",
        "\n",
        "      ticker_data = df_list[0]\n",
        "      #+2022-10-23\n",
        "      ticker_data['date'] = ticker_data['date'].dt.strftime('%Y-%m-%d')\n",
        "      temp['date'] = temp['date'].dt.strftime('%Y-%m-%d')\n",
        "      #-2022-10-23\n",
        "\n",
        "      if len(df_list) > 0:\n",
        "        for index in range(1,len(df_list)):\n",
        "            interval = df_list[index].columns[0]\n",
        "            temp = df_list[index].rename(columns={interval: 'date'})\n",
        "            ticker_data = consolidate(ticker_data, temp, interval)\n",
        "\n",
        "      ticker_data.columns = ['{}{}'.format(c, '' if c == 'date' else '_'+ticker) for c in ticker_data.columns]\n",
        "      data_temp_list.append(ticker_data)\n",
        "      sleep(0) # limit api calls 300 requests 10 seg\n",
        "\n",
        "    for index in range(0,len(data_temp_list)):\n",
        "        interval = data_temp_list[index].columns[0]\n",
        "        temp = data_temp_list[index].rename(columns={interval: 'date'})\n",
        "        #temp['date'] = temp['date'].apply(lambda x: x.strftime('%Y-%m-%d')) -2022-10-23\n",
        "        if len(data_temp_list[index]) > 0:\n",
        "          temp['date'] = pd.to_datetime(temp['date'])\n",
        "        if index == 0:\n",
        "          data_temp = temp\n",
        "        else:\n",
        "          data_temp = consolidate(data_temp, temp, interval)\n",
        "\n",
        "    data_temp['date_num'] = data_temp['date'].apply(dt.date.toordinal) - 693594 #get it in date_num in excel\n",
        "    data_temp = data_temp[data_temp.date_num > 0]\n",
        "\n",
        "    data_temp = data_temp.sort_values(by=['date']).fillna(method=\"ffill\")\n",
        "    data_temp.pop('date')\n",
        "    output | 'Write' >> data_temp.to_csv(data_filename, index=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  logging.getLogger().setLevel(logging.INFO)\n",
        "  run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}